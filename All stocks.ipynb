{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "# avg_open_price = 0\n",
    "\n",
    "def dataFrame_maker(n,sup):\n",
    "    global df,total_trades\n",
    "    lol = pd.read_csv('cm{}AUG2021bhav.csv'.format(n))\n",
    "    lol = lol[lol['SERIES'] == 'EQ']\n",
    "    lol = lol[lol['CLOSE'] >= 100]\n",
    "    lol = lol[lol['TOTALTRADES'] >= 10000]\n",
    "    lol[n] = ((lol['CLOSE'] - lol['OPEN'])*100 / lol['OPEN']).round(2)\n",
    "    lol = lol[['SYMBOL',n]]\n",
    "    \n",
    "    if sup == 1:\n",
    "        df = lol.merge(df,on='SYMBOL')\n",
    "    else:\n",
    "        df = lol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>23</th>\n",
       "      <th>20</th>\n",
       "      <th>18</th>\n",
       "      <th>17</th>\n",
       "      <th>16</th>\n",
       "      <th>13</th>\n",
       "      <th>12</th>\n",
       "      <th>11</th>\n",
       "      <th>10</th>\n",
       "      <th>09</th>\n",
       "      <th>06</th>\n",
       "      <th>05</th>\n",
       "      <th>04</th>\n",
       "      <th>03</th>\n",
       "      <th>02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARTIIND</td>\n",
       "      <td>-2.68</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>3.16</td>\n",
       "      <td>-2.93</td>\n",
       "      <td>-3.77</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABFRL</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACC</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADANIENT</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>-2.79</td>\n",
       "      <td>-3.45</td>\n",
       "      <td>8.06</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADANIPORTS</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>2.56</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-3.25</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>VOLTAS</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.32</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-1.89</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-1.77</td>\n",
       "      <td>-1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>WIPRO</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>3.45</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>ZEEL</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>-2.10</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>-4.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-2.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>ZENSARTECH</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>-3.03</td>\n",
       "      <td>3.82</td>\n",
       "      <td>3.82</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>5.31</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>-3.53</td>\n",
       "      <td>-3.52</td>\n",
       "      <td>1.81</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ZOMATO</td>\n",
       "      <td>-7.66</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>2.61</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>10.28</td>\n",
       "      <td>-4.43</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-3.06</td>\n",
       "      <td>-2.74</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SYMBOL    23    20    18    17    16    13    12     11    10    09  \\\n",
       "0      AARTIIND -2.68 -2.61 -0.29  0.49 -0.13  0.87  0.39  -0.59 -2.99 -1.38   \n",
       "1         ABFRL -3.96 -0.47 -1.01  0.17 -0.05 -1.15  0.33   0.90 -1.74 -1.53   \n",
       "2           ACC -1.68 -1.70  1.78  0.38 -0.59  0.57  0.60  -0.91 -1.16 -1.51   \n",
       "3      ADANIENT -1.30 -0.55  1.26  0.74 -0.10 -0.55 -0.05  -1.23 -2.79 -3.45   \n",
       "4    ADANIPORTS -3.40 -0.41  1.29 -1.86  0.41 -0.04  0.44   0.83 -1.24 -1.97   \n",
       "..          ...   ...   ...   ...   ...   ...   ...   ...    ...   ...   ...   \n",
       "194      VOLTAS -0.90 -0.74 -0.08 -0.07  1.32 -0.02 -1.89   0.40 -2.42 -2.61   \n",
       "195       WIPRO  0.46 -0.39 -1.00  3.45 -0.33  1.57  0.64  -0.11  0.91 -0.53   \n",
       "196        ZEEL -1.08 -2.10 -1.48 -1.73 -1.25 -1.40  1.26  -1.84 -4.83  0.66   \n",
       "197  ZENSARTECH -1.20 -2.18 -3.03  3.82  3.82 -0.26  5.31  -1.69 -3.53 -3.52   \n",
       "198      ZOMATO -7.66  3.22  0.33 -0.23 -1.06  2.61 -0.15  10.28 -4.43 -1.36   \n",
       "\n",
       "       06    05    04    03    02  \n",
       "0    3.16 -2.93 -3.77  2.23  0.23  \n",
       "1   -0.54 -1.62 -3.24 -1.25 -1.10  \n",
       "2   -1.71 -0.33 -1.41  0.54  1.21  \n",
       "3    8.06  0.30 -2.09 -1.65  0.22  \n",
       "4    2.56 -0.21 -3.25  1.01  1.47  \n",
       "..    ...   ...   ...   ...   ...  \n",
       "194 -0.10  0.70 -0.97 -1.77 -1.44  \n",
       "195 -0.95  0.57 -1.11 -0.76  0.69  \n",
       "196 -2.50 -0.88 -2.65  0.64 -0.83  \n",
       "197  1.81 -0.32  0.40  0.55 -2.22  \n",
       "198 -3.06 -2.74 -1.00  1.75  2.91  \n",
       "\n",
       "[199 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame_maker('02',0)\n",
    "\n",
    "array = ['03','04','05','06','09','10','11','12','13','16','17','18','20','23']\n",
    "\n",
    "for i in array:\n",
    "    dataFrame_maker(i,1)\n",
    "\n",
    "df.dropna(axis=0,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Categorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>20</th>\n",
       "      <th>18</th>\n",
       "      <th>17</th>\n",
       "      <th>16</th>\n",
       "      <th>13</th>\n",
       "      <th>12</th>\n",
       "      <th>11</th>\n",
       "      <th>10</th>\n",
       "      <th>09</th>\n",
       "      <th>06</th>\n",
       "      <th>05</th>\n",
       "      <th>04</th>\n",
       "      <th>03</th>\n",
       "      <th>02</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARTIIND</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>3.16</td>\n",
       "      <td>-2.93</td>\n",
       "      <td>-3.77</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABFRL</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACC</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.21</td>\n",
       "      <td>MEDIUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADANIENT</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>-2.79</td>\n",
       "      <td>-3.45</td>\n",
       "      <td>8.06</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>0.22</td>\n",
       "      <td>MEDIUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADANIPORTS</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>2.56</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-3.25</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.47</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SYMBOL    20    18    17    16    13    12    11    10    09    06  \\\n",
       "0    AARTIIND -2.61 -0.29  0.49 -0.13  0.87  0.39 -0.59 -2.99 -1.38  3.16   \n",
       "1       ABFRL -0.47 -1.01  0.17 -0.05 -1.15  0.33  0.90 -1.74 -1.53 -0.54   \n",
       "2         ACC -1.70  1.78  0.38 -0.59  0.57  0.60 -0.91 -1.16 -1.51 -1.71   \n",
       "3    ADANIENT -0.55  1.26  0.74 -0.10 -0.55 -0.05 -1.23 -2.79 -3.45  8.06   \n",
       "4  ADANIPORTS -0.41  1.29 -1.86  0.41 -0.04  0.44  0.83 -1.24 -1.97  2.56   \n",
       "\n",
       "     05    04    03    02  output  \n",
       "0 -2.93 -3.77  2.23  0.23     LOW  \n",
       "1 -1.62 -3.24 -1.25 -1.10     LOW  \n",
       "2 -0.33 -1.41  0.54  1.21  MEDIUM  \n",
       "3  0.30 -2.09 -1.65  0.22  MEDIUM  \n",
       "4 -0.21 -3.25  1.01  1.47     LOW  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Output_categorization(change):\n",
    "    if change <=-4.5:\n",
    "        return \"VERY LOW\"\n",
    "    elif change >-4.5 and change <=-2 :\n",
    "        return \"LOW\"\n",
    "    elif change >-2 and change <= 2:\n",
    "        return \"MEDIUM\"\n",
    "    elif change >2 and change<=4.5:\n",
    "        return \"HIGH\"\n",
    "    elif change >4.5:\n",
    "        return \"VERY HIGH\"\n",
    "    \n",
    "# Change in words\n",
    "df['output'] = df['23'].apply(Output_categorization)\n",
    "df = df.drop(['23'], axis = 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MEDIUM      99\n",
       "LOW         64\n",
       "VERY LOW    30\n",
       "HIGH         6\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,1:-1]\n",
    "y = df['output']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>MEDIUM</th>\n",
       "      <th>VERY LOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HIGH  LOW  MEDIUM  VERY LOW\n",
       "0       0    1       0         0\n",
       "1       0    1       0         0\n",
       "2       0    0       1         0\n",
       "3       0    0       1         0\n",
       "4       0    1       0         0\n",
       "..    ...  ...     ...       ...\n",
       "194     0    0       1         0\n",
       "195     0    0       1         0\n",
       "196     0    0       1         0\n",
       "197     0    0       1         0\n",
       "198     0    0       0         1\n",
       "\n",
       "[199 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y,columns=['y'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 19ms/step - loss: 1.3725 - accuracy: 0.0645 - val_loss: 1.2431 - val_accuracy: 0.1087\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.3210 - accuracy: 0.0753 - val_loss: 1.2117 - val_accuracy: 0.1304\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2829 - accuracy: 0.0860 - val_loss: 1.1834 - val_accuracy: 0.1304\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2493 - accuracy: 0.0968 - val_loss: 1.1574 - val_accuracy: 0.1304\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2176 - accuracy: 0.0968 - val_loss: 1.1336 - val_accuracy: 0.1304\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1888 - accuracy: 0.1075 - val_loss: 1.1108 - val_accuracy: 0.1304\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1615 - accuracy: 0.1075 - val_loss: 1.0896 - val_accuracy: 0.1304\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1347 - accuracy: 0.1075 - val_loss: 1.0702 - val_accuracy: 0.1304\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1122 - accuracy: 0.1183 - val_loss: 1.0514 - val_accuracy: 0.1304\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0898 - accuracy: 0.1183 - val_loss: 1.0344 - val_accuracy: 0.1522\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0691 - accuracy: 0.1183 - val_loss: 1.0186 - val_accuracy: 0.1522\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0500 - accuracy: 0.1290 - val_loss: 1.0041 - val_accuracy: 0.1522\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0315 - accuracy: 0.1290 - val_loss: 0.9905 - val_accuracy: 0.1522\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0161 - accuracy: 0.1290 - val_loss: 0.9764 - val_accuracy: 0.1522\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9985 - accuracy: 0.1398 - val_loss: 0.9636 - val_accuracy: 0.1522\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9834 - accuracy: 0.1398 - val_loss: 0.9511 - val_accuracy: 0.1739\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9687 - accuracy: 0.1720 - val_loss: 0.9393 - val_accuracy: 0.1739\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9543 - accuracy: 0.1720 - val_loss: 0.9282 - val_accuracy: 0.1739\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9410 - accuracy: 0.1720 - val_loss: 0.9170 - val_accuracy: 0.1739\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9272 - accuracy: 0.1828 - val_loss: 0.9061 - val_accuracy: 0.1739\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9152 - accuracy: 0.1935 - val_loss: 0.8953 - val_accuracy: 0.1739\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9021 - accuracy: 0.1935 - val_loss: 0.8855 - val_accuracy: 0.1739\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8906 - accuracy: 0.1935 - val_loss: 0.8758 - val_accuracy: 0.1739\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8792 - accuracy: 0.2043 - val_loss: 0.8663 - val_accuracy: 0.1739\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8671 - accuracy: 0.2151 - val_loss: 0.8580 - val_accuracy: 0.1957\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8574 - accuracy: 0.2151 - val_loss: 0.8491 - val_accuracy: 0.1957\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8470 - accuracy: 0.2151 - val_loss: 0.8408 - val_accuracy: 0.1957\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8370 - accuracy: 0.2258 - val_loss: 0.8326 - val_accuracy: 0.1957\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8272 - accuracy: 0.2473 - val_loss: 0.8247 - val_accuracy: 0.2174\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8179 - accuracy: 0.2473 - val_loss: 0.8172 - val_accuracy: 0.2391\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8089 - accuracy: 0.2473 - val_loss: 0.8098 - val_accuracy: 0.2391\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8003 - accuracy: 0.2473 - val_loss: 0.8029 - val_accuracy: 0.2391\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7920 - accuracy: 0.2473 - val_loss: 0.7960 - val_accuracy: 0.2391\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7838 - accuracy: 0.2688 - val_loss: 0.7894 - val_accuracy: 0.2391\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7759 - accuracy: 0.2688 - val_loss: 0.7829 - val_accuracy: 0.2391\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7678 - accuracy: 0.2796 - val_loss: 0.7767 - val_accuracy: 0.2609\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7603 - accuracy: 0.2903 - val_loss: 0.7706 - val_accuracy: 0.2609\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7527 - accuracy: 0.2903 - val_loss: 0.7647 - val_accuracy: 0.2826\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7457 - accuracy: 0.3011 - val_loss: 0.7590 - val_accuracy: 0.2826\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7390 - accuracy: 0.3011 - val_loss: 0.7535 - val_accuracy: 0.2826\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7322 - accuracy: 0.3011 - val_loss: 0.7488 - val_accuracy: 0.2826\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7263 - accuracy: 0.3011 - val_loss: 0.7438 - val_accuracy: 0.3043\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7207 - accuracy: 0.3118 - val_loss: 0.7389 - val_accuracy: 0.3043\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7146 - accuracy: 0.3118 - val_loss: 0.7348 - val_accuracy: 0.3043\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7094 - accuracy: 0.3118 - val_loss: 0.7304 - val_accuracy: 0.3043\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7043 - accuracy: 0.3118 - val_loss: 0.7263 - val_accuracy: 0.3043\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6992 - accuracy: 0.3118 - val_loss: 0.7224 - val_accuracy: 0.3043\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.3118 - val_loss: 0.7188 - val_accuracy: 0.3043\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6903 - accuracy: 0.3118 - val_loss: 0.7150 - val_accuracy: 0.3261\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.3118 - val_loss: 0.7115 - val_accuracy: 0.3261\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.3333 - val_loss: 0.7075 - val_accuracy: 0.3478\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6768 - accuracy: 0.3333 - val_loss: 0.7038 - val_accuracy: 0.3478\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.3441 - val_loss: 0.7003 - val_accuracy: 0.3478\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.3441 - val_loss: 0.6972 - val_accuracy: 0.3478\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.3441 - val_loss: 0.6938 - val_accuracy: 0.3478\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.3441 - val_loss: 0.6906 - val_accuracy: 0.3478\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6570 - accuracy: 0.3441 - val_loss: 0.6876 - val_accuracy: 0.3478\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6533 - accuracy: 0.3441 - val_loss: 0.6846 - val_accuracy: 0.3478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.3656 - val_loss: 0.6816 - val_accuracy: 0.3478\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.3656 - val_loss: 0.6786 - val_accuracy: 0.3478\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.3763 - val_loss: 0.6757 - val_accuracy: 0.3478\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.3656 - val_loss: 0.6727 - val_accuracy: 0.3478\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6355 - accuracy: 0.3656 - val_loss: 0.6700 - val_accuracy: 0.3478\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.3656 - val_loss: 0.6672 - val_accuracy: 0.3478\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6289 - accuracy: 0.3656 - val_loss: 0.6645 - val_accuracy: 0.3478\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.3656 - val_loss: 0.6621 - val_accuracy: 0.3478\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6229 - accuracy: 0.3656 - val_loss: 0.6597 - val_accuracy: 0.3478\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.3656 - val_loss: 0.6573 - val_accuracy: 0.3478\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6173 - accuracy: 0.3656 - val_loss: 0.6547 - val_accuracy: 0.3478\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.3656 - val_loss: 0.6524 - val_accuracy: 0.3478\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6115 - accuracy: 0.3548 - val_loss: 0.6500 - val_accuracy: 0.3478\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.3548 - val_loss: 0.6477 - val_accuracy: 0.3696\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6059 - accuracy: 0.3656 - val_loss: 0.6454 - val_accuracy: 0.3696\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6032 - accuracy: 0.3656 - val_loss: 0.6432 - val_accuracy: 0.3696\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.3656 - val_loss: 0.6410 - val_accuracy: 0.3696\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.3871 - val_loss: 0.6388 - val_accuracy: 0.3696\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.3871 - val_loss: 0.6367 - val_accuracy: 0.3696\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.3871 - val_loss: 0.6346 - val_accuracy: 0.3696\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5906 - accuracy: 0.3871 - val_loss: 0.6326 - val_accuracy: 0.3696\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5883 - accuracy: 0.3871 - val_loss: 0.6307 - val_accuracy: 0.3696\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.3871 - val_loss: 0.6287 - val_accuracy: 0.3696\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.3871 - val_loss: 0.6268 - val_accuracy: 0.3696\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.3871 - val_loss: 0.6251 - val_accuracy: 0.3696\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5790 - accuracy: 0.3978 - val_loss: 0.6233 - val_accuracy: 0.3696\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.3978 - val_loss: 0.6216 - val_accuracy: 0.3696\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.3978 - val_loss: 0.6197 - val_accuracy: 0.3696\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.3978 - val_loss: 0.6180 - val_accuracy: 0.3696\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5706 - accuracy: 0.4086 - val_loss: 0.6163 - val_accuracy: 0.3696\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.4086 - val_loss: 0.6147 - val_accuracy: 0.3696\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.4086 - val_loss: 0.6131 - val_accuracy: 0.3913\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5648 - accuracy: 0.4086 - val_loss: 0.6117 - val_accuracy: 0.3913\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.4194 - val_loss: 0.6103 - val_accuracy: 0.4130\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5613 - accuracy: 0.4194 - val_loss: 0.6088 - val_accuracy: 0.4130\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.4194 - val_loss: 0.6073 - val_accuracy: 0.4348\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5575 - accuracy: 0.4194 - val_loss: 0.6059 - val_accuracy: 0.4348\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.4301 - val_loss: 0.6044 - val_accuracy: 0.4348\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5539 - accuracy: 0.4301 - val_loss: 0.6030 - val_accuracy: 0.4348\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.4301 - val_loss: 0.6016 - val_accuracy: 0.4348\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.4301 - val_loss: 0.6002 - val_accuracy: 0.4348\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.4301 - val_loss: 0.5989 - val_accuracy: 0.4348\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LeakyReLU,PReLU,ELU,Dropout,Activation,Embedding,Flatten,BatchNormalization\n",
    "from keras.activations import relu,sigmoid\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# output_dim or unit is for output layer ; kernel_initializer or init\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense( units= 6, kernel_initializer = 'he_uniform',activation='relu',input_dim = 14))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 4, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # the neural network can have layers between 2 to 20 \n",
    "    for i in range(hp.Int('num_layers',2,20)):\n",
    "        model.add(keras.layers.Dense(\n",
    "            # neurons will be chaning between 32 and 512 , where its added 32 ea\n",
    "            units = hp.Int('units_'+str(i),min_value=32,max_value=512,step=32),\n",
    "            activation = 'relu'\n",
    "        ))\n",
    "        model.add(keras.layers.Dense(4,activation='Softmax'))         # output layer , acitvation linear as it regressions \n",
    "        model.compile(\n",
    "            # Random search will select from this learning rates\n",
    "            optimizer = keras.optimizers.Adam(hp.Choice('learning_rate',[1e-2,1e-3,1e-4])),\n",
    "            loss = keras.losses.CategoricalCrossentropy(),\n",
    "#             loss= keras.losses.categorical_crossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    return model\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 5,\n",
    "    executions_per_trial =3,\n",
    "    directory = 'project3',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 03s]\n",
      "val_accuracy: 0.5055555502573649\n",
      "\n",
      "Best val_accuracy So Far: 0.5055555502573649\n",
      "Total elapsed time: 00h 00m 28s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_test,y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_tuner.engine.hyperparameters.HyperParameters at 0x7f8993682250>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0.01\n",
      "128\n",
      "416\n",
      "512\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(best_hps.get('num_layers'))\n",
    "print(best_hps.get('learning_rate'))\n",
    "print(best_hps.get('units_1'))\n",
    "print(best_hps.get('units_2'))\n",
    "print(best_hps.get('units_3'))\n",
    "print(best_hps.get('units_4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 20ms/step - loss: 1.8345 - accuracy: 0.3226 - val_loss: 0.5560 - val_accuracy: 0.1957\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5241 - accuracy: 0.3763 - val_loss: 0.5134 - val_accuracy: 0.4130\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5019 - accuracy: 0.4946 - val_loss: 0.5190 - val_accuracy: 0.4565\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.5591 - val_loss: 0.6165 - val_accuracy: 0.4130\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4243 - accuracy: 0.6344 - val_loss: 0.5191 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.6667 - val_loss: 0.5797 - val_accuracy: 0.4130\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3483 - accuracy: 0.6667 - val_loss: 0.6815 - val_accuracy: 0.3913\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3030 - accuracy: 0.7204 - val_loss: 0.8170 - val_accuracy: 0.3696\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2620 - accuracy: 0.7097 - val_loss: 1.0462 - val_accuracy: 0.4348\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2424 - accuracy: 0.7312 - val_loss: 1.0075 - val_accuracy: 0.3696\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1474 - accuracy: 0.8495 - val_loss: 1.4047 - val_accuracy: 0.3696\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2198 - accuracy: 0.8387 - val_loss: 1.7950 - val_accuracy: 0.3043\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2452 - accuracy: 0.8280 - val_loss: 1.1802 - val_accuracy: 0.3696\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2869 - accuracy: 0.7849 - val_loss: 1.2553 - val_accuracy: 0.3478\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2487 - accuracy: 0.7957 - val_loss: 1.1997 - val_accuracy: 0.3478\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1228 - accuracy: 0.8495 - val_loss: 1.7156 - val_accuracy: 0.3696\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1261 - accuracy: 0.8817 - val_loss: 2.0919 - val_accuracy: 0.3043\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0704 - accuracy: 0.9140 - val_loss: 1.8773 - val_accuracy: 0.3478\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1475 - accuracy: 0.8925 - val_loss: 2.1197 - val_accuracy: 0.3696\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1067 - accuracy: 0.8817 - val_loss: 1.8145 - val_accuracy: 0.3261\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1869 - accuracy: 0.8925 - val_loss: 1.6295 - val_accuracy: 0.3261\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0951 - accuracy: 0.9570 - val_loss: 2.2401 - val_accuracy: 0.3261\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0515 - accuracy: 0.9570 - val_loss: 2.3885 - val_accuracy: 0.3696\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0454 - accuracy: 0.9570 - val_loss: 2.9156 - val_accuracy: 0.3478\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0483 - accuracy: 0.9570 - val_loss: 3.1109 - val_accuracy: 0.3478\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0496 - accuracy: 0.9462 - val_loss: 2.9441 - val_accuracy: 0.3478\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2294 - accuracy: 0.9247 - val_loss: 2.9028 - val_accuracy: 0.3043\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0565 - accuracy: 0.9247 - val_loss: 2.7030 - val_accuracy: 0.3478\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9785 - val_loss: 2.8128 - val_accuracy: 0.3261\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0436 - accuracy: 0.9892 - val_loss: 3.1511 - val_accuracy: 0.3261\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 3.3850 - val_accuracy: 0.3261\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0213 - accuracy: 0.9892 - val_loss: 3.8204 - val_accuracy: 0.3261\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 4.0448 - val_accuracy: 0.3478\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 4.1313 - val_accuracy: 0.3478\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0179 - accuracy: 0.9785 - val_loss: 4.1812 - val_accuracy: 0.3478\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 4.2294 - val_accuracy: 0.3478\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 4.2724 - val_accuracy: 0.3478\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 4.3157 - val_accuracy: 0.3478\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 4.3707 - val_accuracy: 0.3478\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 4.4420 - val_accuracy: 0.3478\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 4.5282 - val_accuracy: 0.3478\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 4.6573 - val_accuracy: 0.3478\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 4.8317 - val_accuracy: 0.3478\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 4.9886 - val_accuracy: 0.3261\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 5.1512 - val_accuracy: 0.3261\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 5.2917 - val_accuracy: 0.3261\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 5.4680 - val_accuracy: 0.3261\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 5.6094 - val_accuracy: 0.3261\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 5.7480 - val_accuracy: 0.3261\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 5.9754 - val_accuracy: 0.3261\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 6.1235 - val_accuracy: 0.3261\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 6.4123 - val_accuracy: 0.3261\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 6.4641 - val_accuracy: 0.3261\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 6.4891 - val_accuracy: 0.3261\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 6.5471 - val_accuracy: 0.3261\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 6.6744 - val_accuracy: 0.3261\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 6.7288 - val_accuracy: 0.3261\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 6.5258 - val_accuracy: 0.3478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1322 - accuracy: 0.9892 - val_loss: 6.4062 - val_accuracy: 0.3478\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2345 - accuracy: 0.8925 - val_loss: 4.8331 - val_accuracy: 0.4348\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.9110 - accuracy: 0.7849 - val_loss: 2.8695 - val_accuracy: 0.2609\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3653 - accuracy: 0.6452 - val_loss: 0.8998 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.6344 - val_loss: 2.7252 - val_accuracy: 0.3696\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.7312 - val_loss: 0.9038 - val_accuracy: 0.2609\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3695 - accuracy: 0.6989 - val_loss: 1.1692 - val_accuracy: 0.3478\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1918 - accuracy: 0.8172 - val_loss: 1.9148 - val_accuracy: 0.3478\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1868 - accuracy: 0.8387 - val_loss: 3.0417 - val_accuracy: 0.3261\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1235 - accuracy: 0.9140 - val_loss: 4.2740 - val_accuracy: 0.3478\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.9355 - val_loss: 4.2429 - val_accuracy: 0.4565\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9247 - val_loss: 4.1900 - val_accuracy: 0.3913\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9677 - val_loss: 5.2578 - val_accuracy: 0.3478\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3088 - accuracy: 0.9462 - val_loss: 3.3207 - val_accuracy: 0.2826\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0339 - accuracy: 0.9785 - val_loss: 4.6957 - val_accuracy: 0.2826\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0661 - accuracy: 0.9677 - val_loss: 4.4808 - val_accuracy: 0.2826\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 4.4222 - val_accuracy: 0.3261\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.6536 - val_accuracy: 0.3043\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.8578 - val_accuracy: 0.3043\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 6.7795e-04 - accuracy: 1.0000 - val_loss: 5.0442 - val_accuracy: 0.3261\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4.1847e-04 - accuracy: 1.0000 - val_loss: 5.2107 - val_accuracy: 0.3478\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.7956e-04 - accuracy: 1.0000 - val_loss: 5.3536 - val_accuracy: 0.3478\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.9628e-04 - accuracy: 1.0000 - val_loss: 5.4545 - val_accuracy: 0.3478\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.6013e-04 - accuracy: 1.0000 - val_loss: 5.5603 - val_accuracy: 0.3261\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3344e-04 - accuracy: 1.0000 - val_loss: 5.7032 - val_accuracy: 0.3261\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0243e-04 - accuracy: 1.0000 - val_loss: 5.8629 - val_accuracy: 0.3261\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.9441e-05 - accuracy: 1.0000 - val_loss: 6.0707 - val_accuracy: 0.3261\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.1109e-05 - accuracy: 1.0000 - val_loss: 6.1893 - val_accuracy: 0.3478\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 5.1075e-05 - accuracy: 1.0000 - val_loss: 6.2311 - val_accuracy: 0.3478\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 4.2902e-05 - accuracy: 1.0000 - val_loss: 6.3518 - val_accuracy: 0.3478\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.7233e-05 - accuracy: 1.0000 - val_loss: 6.4837 - val_accuracy: 0.3478\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.9975e-05 - accuracy: 1.0000 - val_loss: 6.5870 - val_accuracy: 0.3478\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.5732e-05 - accuracy: 1.0000 - val_loss: 6.6590 - val_accuracy: 0.3261\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.1725e-05 - accuracy: 1.0000 - val_loss: 6.7635 - val_accuracy: 0.3261\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.8042e-05 - accuracy: 1.0000 - val_loss: 6.8933 - val_accuracy: 0.3261\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.3691e-05 - accuracy: 1.0000 - val_loss: 7.0699 - val_accuracy: 0.3261\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0268e-05 - accuracy: 1.0000 - val_loss: 7.1770 - val_accuracy: 0.3261\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.8802e-06 - accuracy: 1.0000 - val_loss: 7.2700 - val_accuracy: 0.3261\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.9317e-06 - accuracy: 1.0000 - val_loss: 7.3301 - val_accuracy: 0.3261\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 6.2109e-06 - accuracy: 1.0000 - val_loss: 7.3645 - val_accuracy: 0.3043\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.4202e-06 - accuracy: 1.0000 - val_loss: 7.4123 - val_accuracy: 0.3043\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.9799e-06 - accuracy: 1.0000 - val_loss: 7.4669 - val_accuracy: 0.3043\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# output_dim or unit is for output layer ; kernel_initializer or init\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense( units= 128, kernel_initializer = 'he_uniform',activation='relu',input_dim = 14))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 416, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 512, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 32, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 4, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = keras.optimizers.Adam(0.01), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol.to_csv(r'jeez bredth1.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd09043f088b5ada3303788f898933593b6369d15d1dcd091dac703a7e64d4ef4cb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
